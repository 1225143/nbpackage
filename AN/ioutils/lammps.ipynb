{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from numbers import Integral, Number\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ase import Atoms\n",
    "from ase.io import read\n",
    "from ase.data import atomic_masses, atomic_numbers\n",
    "from ase.build import make_supercell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lammps():\n",
    "    header_tags = [\"atoms\", \"bonds\", \"angles\", \"dihedrals\", \"impropers\"]\n",
    "    header_tags_types = [\n",
    "        \"atom types\",\n",
    "        \"bond types\",\n",
    "        \"angle types\",\n",
    "        \"dihedral types\",\n",
    "        \"improper types\",\n",
    "    ]\n",
    "\n",
    "    tags_atomic = [\"Masses\", \"Atoms\", \"Velocities\"]\n",
    "    tags_interactions = [\"Bonds\", \"Angles\", \"Dihedrals\", \"Impropers\",]\n",
    "    tags_coeffs = [\n",
    "        \"Pair Coeffs\",\n",
    "        \"Nonbond Coeffs\",\n",
    "        \"Bond Coeffs\",\n",
    "        \"Angle Coeffs\",\n",
    "        \"Dihedral Coeffs\",\n",
    "        \"Improper Coeffs\",\n",
    "        \"BondBond Coeffs\",\n",
    "        \"BondAngle Coeffs\",\n",
    "        \"MiddleBondTorsion Coeffs\",\n",
    "        \"EndBondTorsion Coeffs\",\n",
    "        \"AngleTorsion Coeffs\",\n",
    "        \"AngleAngleTorsion Coeffs\",\n",
    "        \"BondBond13 Coeffs\",\n",
    "        \"AngleAngle Coeffs\",\n",
    "    ]\n",
    "    def __init__(self, filename=None):\n",
    "        self.data = dict()\n",
    "        if filename is not None:\n",
    "            self.filename = filename\n",
    "            self.path = Path(filename).resolve()\n",
    "\n",
    "    def get_formatter(self, x):\n",
    "        if issubclass(x, Integral):\n",
    "            return lambda _:f'{_:6d}'\n",
    "        elif issubclass(x, Number):\n",
    "            return lambda _:f'{_:12.8f}'\n",
    "        else:\n",
    "            return lambda _:f'{_}'\n",
    "\n",
    "    def write_data(self, filename, data=None):\n",
    "        \"\"\" alias for self.write_lammpsdata. \"\"\"\n",
    "        self.write_lammpsdata(filename, data=data)\n",
    "\n",
    "\n",
    "    def write_lammpsdata(self, filename, data=None):\n",
    "        if data is None:\n",
    "            data = self.data\n",
    "        now = datetime.now().strftime(\"%Y%M%d-%H%m%S\")\n",
    "        title = data.get('title') or f'Lammps data file created by nbpackage.AN.ioutils {now}'\n",
    "        \n",
    "        header = ''\n",
    "        for tags in (self.header_tags, self.header_tags_types):\n",
    "            for _tag in tags:\n",
    "                if _tag in self.data:\n",
    "                    _formatter = self.get_formatter(int)\n",
    "                    header += _formatter(data[_tag]) + f' {_tag}\\n'\n",
    "            header += '\\n'\n",
    "    \n",
    "        for _x in ('x', 'y', 'z'):\n",
    "            if f'{_x}lo' in data:\n",
    "                _tag_low, _tag_high = f'{_x}lo', f'{_x}hi'\n",
    "                header += f'{data[_tag_low]} {data[_tag_high]} {_tag_low} {_tag_high}\\n'\n",
    "        \n",
    "        header = header.rstrip(\"\\n\") + '\\n\\n'  # remove extra line breaks.\n",
    "\n",
    "        body = ''\n",
    "        for _tag in ('Masses', *self.tags_coeffs, 'Atoms', 'Velocities', *self.tags_interactions):\n",
    "            if _tag in data:\n",
    "                body += f'{_tag}\\n\\n'\n",
    "                _formatters = [self.get_formatter(_.type) for _ in data[_tag].dtypes]\n",
    "                body += data[_tag].to_string(index=False, header=False, formatters=_formatters)\n",
    "                body += '\\n\\n'\n",
    "        body = body.rstrip('\\n') + '\\n'\n",
    "\n",
    "        lines = f'{title}\\n\\n{header}{body}'\n",
    "        if filename is None:\n",
    "            return lines\n",
    "        else:\n",
    "            path = Path(filename)\n",
    "            path.write_text(lines)\n",
    "        \n",
    "    def check_ligpargen_format(self, filename):\n",
    "        with open(filename) as f:\n",
    "            lines = f.read()\n",
    "        return lines\n",
    "\n",
    "    def unique_data(self, data=None):\n",
    "\n",
    "        if data is None:\n",
    "            data = self.data\n",
    "        \n",
    "        def _sort(data, key, map): \n",
    "                data[key] = data[key].iloc[indx]\n",
    "                data[key].loc[:, ['type']] = data[key]['type'].apply(lambda x:_map[x])\n",
    "                data[key] = data[key].sort_values(by='type').reset_index(drop=True)\n",
    "                return data\n",
    "     \n",
    "        if 'Pair Coeffs' in data and 'Masses' in data: \n",
    "            _data = pd.merge(data['Pair Coeffs'], data['Masses'], on='type')\n",
    "            _data = _data[[ 'coeff0', 'coeff1', 'mass']]\n",
    "            a, indx, inv, count = np.unique(_data.values, return_index=True, return_inverse=True, return_counts=True, axis=0)\n",
    "            if len(_data) > len(indx):\n",
    "                # print(len(_data), len(indx))\n",
    "                _map = dict(zip(sorted(indx+1), np.arange(1, len(indx)+1)))\n",
    "                for _key in ('Pair Coeffs', 'Masses'):\n",
    "                    data = _sort(data, _key, _map)\n",
    "                _types = [_map[_] for _ in indx[inv]+1]\n",
    "                data['Atoms'].loc[:, ['type']] = _types\n",
    "\n",
    "        for _tag_coeffs, _tag_ints in zip(self.tags_coeffs[2:], self.tags_interactions):\n",
    "            if _tag_coeffs in data:\n",
    "                _cols = [_ for _ in data[_tag_coeffs].columns.values if _.lstrip('coeff').isdigit()]\n",
    "                _data = data[_tag_coeffs][_cols]\n",
    "                a, indx, inv, count = np.unique(_data.values, return_index=True, return_inverse=True, return_counts=True, axis=0)\n",
    "                if len(_data) > len(indx):\n",
    "                    # print(_tag_coeffs, _tag_ints)\n",
    "                    # print(len(_data), len(indx))\n",
    "                    _map = dict(zip(sorted(indx+1), np.arange(1, len(indx)+1)))\n",
    "                    data = _sort(data, _tag_coeffs, _map)\n",
    "                    _types = [_map[_] for _ in indx[inv]+1]\n",
    "                    data[_tag_ints].loc[:, ['type']] = _types\n",
    "\n",
    "        return data\n",
    "\n",
    "    def read_lammpsdata(self, filename=None, replace_data=True):\n",
    "    \n",
    "        data = dict()\n",
    "        if filename is None:\n",
    "            lines = self.path.read_text()\n",
    "        elif isinstance(filename, Path):\n",
    "            lines = filename.read_text()\n",
    "            self.path = filename\n",
    "            self.filename = self.path.as_posix()\n",
    "        elif os.path.exists(filename):\n",
    "            self.filename = filename\n",
    "            self.path = Path(filename).resolve()\n",
    "            lines = self.path.read_text()\n",
    "        else:\n",
    "            lines = filename\n",
    "\n",
    "        lines += '\\n\\n' \n",
    "        data_blocks, lines = self.parse_block_data(lines)\n",
    "        data.update(data_blocks)\n",
    "\n",
    "        data_header, lines = self.parse_header(lines)\n",
    "        data.update(data_header)\n",
    "    \n",
    "        lines = lines.strip()\n",
    "        data['lines_not_parsed'] = lines\n",
    "\n",
    "        if replace_data:\n",
    "            self.data = data\n",
    "        else:\n",
    "            self.data.update(data)\n",
    "\n",
    "        if len(lines)>0:\n",
    "            print(lines)\n",
    "    \n",
    "        return data\n",
    "\n",
    "    def parse_header(self, lines):\n",
    "        \"\"\" Parse header data in lines. \"\"\"\n",
    "        data = dict()\n",
    "        comments = dict()\n",
    "        tags = self.header_tags_types + self.header_tags\n",
    "        \n",
    "        title, lines = lines.split('\\n', 1)\n",
    "        data['title'] = title\n",
    "\n",
    "        for _tag in tags:\n",
    "            p = f'^([-+.\\d\\s]+)({_tag}.*?)$'\n",
    "            match = re.split(p, lines, flags=re.MULTILINE)\n",
    "            if len(match) == 4:\n",
    "                _prev, _value, _match, _next = match\n",
    "                _line = _match.split('#')\n",
    "                if len(_line)>1:\n",
    "                    comments[_tag] = _line[1]\n",
    "                data[_tag] = int(_value)\n",
    "                lines = _prev + _next\n",
    "        data['header comments'] = comments\n",
    "\n",
    "        _lines = lines.strip().splitlines()\n",
    "        lines = []\n",
    "        for _line in _lines:\n",
    "            if 'lo' in _line and 'hi' in _line:\n",
    "                _low, _high, _tag_low, _tag_high = _line.strip().split(None, 3)\n",
    "                _tag_high = _tag_high.split()[0]\n",
    "                data[_tag_low] = float(_low)\n",
    "                data[_tag_high] = float(_high)\n",
    "            else:\n",
    "                lines.append(_line)\n",
    "        others = '\\n'.join(lines)\n",
    "\n",
    "        return data, others\n",
    "\n",
    "    def parse_block_data(self, lines):\n",
    "        \"\"\" Parse block data begin with tags. \"\"\"\n",
    "        \n",
    "        data = dict()\n",
    "        tags = self.tags_atomic +  self.tags_interactions +  self.tags_coeffs\n",
    "        for _tag in tags:\n",
    "            p = f'(^{_tag}\\s*\\n\\n)(.*?)\\n\\n'\n",
    "            match = re.split(p, lines, flags=re.MULTILINE|re.DOTALL)\n",
    "            if len(match) == 4:\n",
    "                _prev, _, _match, _next = match\n",
    "                _lines = re.findall('^.*$', _match, flags=re.MULTILINE)\n",
    "                data[_tag] = _lines\n",
    "                lines = _prev + _next\n",
    "        others = lines    \n",
    "        data = self._parse_block_data(data)\n",
    "\n",
    "        return data, others\n",
    "\n",
    "    def _parse_block_data(self, data):\n",
    "        tags = self.tags_atomic + self.tags_interactions + self.tags_coeffs\n",
    "        for _tag, _lines in data.items():\n",
    "            if _tag in tags:\n",
    "                _lines = [_line.split('#') for _line in _lines]\n",
    "                _comments = ['' if len(_line)==1 else _line[1] for _line in _lines]\n",
    "                _data = [_line[0].split() for _line in _lines]\n",
    "                if _tag in self.tags_interactions:\n",
    "                    _columns = ['id', 'type', *[f'i{_}' for _ in range(len(_data[0])-2)]]\n",
    "                    _data = pd.DataFrame(np.array(_data), dtype=int, columns=_columns)\n",
    "                    _data['comment'] = _comments\n",
    "                elif _tag in self.tags_coeffs:\n",
    "                    _columns = ['type', *[f'coeff{_}' for _ in range(len(_data[0])-1)]]\n",
    "                    _data = pd.DataFrame(_data, columns=_columns)\n",
    "                    _ncols = _data.shape[1]\n",
    "                    for _col in _columns:\n",
    "                        if _data[_col].apply(lambda x:x.lstrip('-').isdigit()).all():\n",
    "                            _data[_col] = _data[_col].astype(int)\n",
    "                        else:\n",
    "                            _data[_col] = _data[_col].astype(float)\n",
    "                elif _tag == 'Masses':\n",
    "                    _data = pd.DataFrame(_data, columns=['type', 'mass'])\n",
    "                    _data['type'] = _data['type'].astype(int)\n",
    "                    _data['mass'] = _data['mass'].astype(float)\n",
    "                    _data['comment'] = _comments\n",
    "                elif _tag == 'Velocity':\n",
    "                    _data = pd.DataFrame(np.array(_data, dtype=float), columns=['atomid', 'x', 'y', 'z'])\n",
    "                    _data['atomid'] = data['atomid'].astype(int)\n",
    "                    _data['comment'] = _comments\n",
    "                elif _tag == 'Atoms':\n",
    "                    _columns = ['id', 'mol-id', 'type', 'q', 'x', 'y', 'z', 'ix', 'iy', 'iz']\n",
    "                    _int_cols = ['id', 'mol-id', 'type', 'ix', 'iy', 'iz']\n",
    "                    if len(_data[0]) == 6:\n",
    "                        _columns.remove('q')\n",
    "                        _data = pd.DataFrame(_data, columns=_columns[:3] + _columns[4:7], dtype=float)\n",
    "                    if len(_data[0]) == 7:\n",
    "                        # atom-tag molecule-tag atom-type q x y z nx ny nz  (nx,ny,nz are optional)\n",
    "                        _data = pd.DataFrame(_data, columns=_columns[:7], dtype=float)\n",
    "                    elif len(_data[0])==10:\n",
    "                        _data = pd.DataFrame(_data, columns=_columns, dtype=float)\n",
    "\n",
    "                    for _col in _int_cols:\n",
    "                        if _col in _data:\n",
    "                            _data[_col] = _data[_col].astype(int)\n",
    "\n",
    "                data[_tag] = _data\n",
    "        return data\n",
    "\n",
    "    def make_supercell(self, p=[5, 5, 5], data=None, reduce_box=False):\n",
    "\n",
    "        if data is None:\n",
    "            data = self.data\n",
    "\n",
    "        if reduce_box:\n",
    "            pos = data['Atoms'].loc[:, ['x', 'y', 'z']].values\n",
    "            box_size = np.max(pos, axis=0) - np.min(pos, axis=0)\n",
    "            data['xhi'] = data['xlo'] + box_size[0]\n",
    "            data['yhi'] = data['ylo'] + box_size[1]\n",
    "            data['zhi'] = data['zlo'] + box_size[2]\n",
    "        \n",
    "        num_cells = np.prod(p)\n",
    "\n",
    "        natoms = len(data['Atoms'])\n",
    "        atoms = self.to_aseAtoms(data=data)\n",
    "        \n",
    "        if isinstance(p, Integral):\n",
    "            supercell = atoms * [p, p, p]\n",
    "        elif np.array(p).ndim == 1 and len(p)==3:\n",
    "            supercell = atoms * p\n",
    "        else:\n",
    "            supercell = make_supercell(atoms, p)\n",
    "        \n",
    "        box = lx, ly, lz, alpha, beta, gamma = supercell.cell.cellpar()\n",
    "        mass_center = supercell.get_center_of_mass()\n",
    "        pos = supercell.positions\n",
    "        print(data['Bonds'].shape)\n",
    "        mol_ids = data['Atoms'].loc[:, 'mol-id']\n",
    "        num_mols = mol_ids.values.max() - mol_ids.values.min() + 1\n",
    "        shift_ids = (np.arange(num_cells) * num_mols).repeat(natoms)\n",
    "        mol_ids = pd.concat([mol_ids]*num_cells).values + shift_ids\n",
    "\n",
    "        atom_ids = data['Atoms'].loc[:, 'id']\n",
    "        shift_ids = (np.arange(num_cells)*natoms).repeat(natoms)\n",
    "        atom_ids = pd.concat([atom_ids]*num_cells).values + shift_ids\n",
    "\n",
    "        data['xhi'] = data['xlo'] + lx\n",
    "        data['yhi'] = data['ylo'] + ly\n",
    "        data['zhi'] = data['zlo'] + lz\n",
    "        for _tag in self.header_tags:\n",
    "            data[_tag] = data[_tag] * num_cells\n",
    "        \n",
    "        for _tag in ['Atoms', 'Velocities']:\n",
    "            if _tag in data:\n",
    "                data[_tag] = pd.concat([data[_tag]]*num_cells).reset_index(drop=True)\n",
    "        \n",
    "        data['Atoms'].loc[:, ['x', 'y', 'z']] = pos\n",
    "        data['Atoms'].loc[:, 'mol-id'] = mol_ids\n",
    "        data['Atoms'].loc[:, 'id'] = atom_ids\n",
    "        print(data['Bonds'].shape)\n",
    "        for _tag in self.tags_interactions:\n",
    "            _ndata = len(data[_tag])\n",
    "            print(_tag, _ndata)\n",
    "            _cols  = data[_tag].columns.tolist()\n",
    "            _cols = [_ for _ in _cols if not _ in ['id', 'type', 'comment']]\n",
    "            shift_ids = (np.arange(num_cells) * natoms).repeat(_ndata)\n",
    "            shift_ids = np.vstack([shift_ids]*len(_cols)).T\n",
    "            print(_tag)\n",
    "            print(shift_ids)\n",
    "            print(shift_ids.shape)\n",
    "            data[_tag] = pd.concat([data[_tag]]*num_cells).reset_index(drop=True)\n",
    "            data[_tag].loc[:, _cols] += shift_ids\n",
    "            shift_ids = (np.arange(num_cells)*_ndata).repeat(_ndata)\n",
    "            print(shift_ids)\n",
    "            data[_tag].loc[:, 'id'] += shift_ids\n",
    "\n",
    "        \n",
    "        new = __class__()\n",
    "        new.data = data\n",
    "        \n",
    "        return new\n",
    "\n",
    "    def to_aseAtoms(self, data=None):\n",
    "        if data is None:\n",
    "            data = self.data\n",
    "        \n",
    "        numbers = self._get_numbers_from_masses(data)\n",
    "        lines = self.write_lammpsdata(filename=None, data=data)\n",
    "        with StringIO() as f:\n",
    "            f.write(lines)\n",
    "            f.seek(0)\n",
    "            atoms = read(f, format='lammps-data')\n",
    "        atoms.numbers = numbers\n",
    "        return atoms\n",
    "\n",
    "            \n",
    "    def _get_numbers_from_masses(self, data): \n",
    "        _int_masses = np.round(atomic_masses).astype(int)\n",
    "        mass_number = dict(zip(_int_masses[1:], np.arange(1, len(_int_masses)-1)))\n",
    "        int_masses = data['Masses']['mass'].values.ravel().round().astype(int)\n",
    "        type_number = {_type: mass_number.get(_m) for _type, _m in zip(data['Masses']['type'], int_masses)}\n",
    "        numbers = [type_number.get(_) for _ in data['Atoms']['type'].values]\n",
    "        return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.arange(3)*0.99).values.ravel().round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([np.arange(3)*0.99]).round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    l = Lammps('../../ligpargen_data/0.data')\n",
    "    data = l.read_lammpsdata()\n",
    "    data = l.unique_data()\n",
    "    print(data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c234fce11f2837fac9d5905a5a3f629cc63d237c9357fcd422f1c8717e73452c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('mi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
